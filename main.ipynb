{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 296,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torchvision\n",
    "import torchvision.transforms as transforms\n",
    "\n",
    "import os\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "\n",
    "# path to the data\n",
    "\n",
    "train_data_path = './train'\n",
    "test_data_path = './test'\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 297,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "100\n"
     ]
    }
   ],
   "source": [
    "print(len(os.listdir('./train')))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 298,
   "metadata": {},
   "outputs": [],
   "source": [
    "# transform for mean and std\n",
    "\n",
    "train_trans_ms = transforms.Compose([transforms.ToTensor()])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 299,
   "metadata": {},
   "outputs": [],
   "source": [
    "# applying transformation and selecting the data \n",
    "\n",
    "train_dataset_ms = torchvision.datasets.ImageFolder(root = train_data_path , transform= train_trans_ms )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 300,
   "metadata": {},
   "outputs": [],
   "source": [
    "# loading the dataset, need to do so in batches or else we run out of RAM\n",
    "\n",
    "train_loader_ms = torch.utils.data.DataLoader(dataset = train_dataset_ms, batch_size = 32, shuffle=False)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 301,
   "metadata": {},
   "outputs": [],
   "source": [
    "# function for calculating std and mean\n",
    "\n",
    "def get_mean_and_std(loader):\n",
    "    mean = 0.\n",
    "    std = 0.\n",
    "    total_img_count = 0\n",
    "    # looping thrue each batch\n",
    "    for images, _ in loader:\n",
    "        # number of images in batch\n",
    "        images_count_in_batch = images.size(0)\n",
    "        # resizeing the image tensor in the batch in order to reduce the dimensions of the tensor form 4 to 3\n",
    "        images = images.view(images_count_in_batch, images.size(1), -1)\n",
    "        mean += images.mean(2).sum(0)\n",
    "        std += images.std(2).sum(0)\n",
    "        total_img_count += images_count_in_batch\n",
    "\n",
    "    mean /= total_img_count\n",
    "    std /= total_img_count\n",
    "\n",
    "# return a proxy mean and std , we cant get the real one because we cant load the whole data set, so we calculate the avrage for each batch and then the avrage for all the batches \n",
    "    return mean,std\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 302,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([0.4714, 0.4700, 0.4550])\n",
      "tensor([0.2398, 0.2303, 0.2324])\n"
     ]
    }
   ],
   "source": [
    "# returns the mean and std\n",
    "\n",
    "mean , std = get_mean_and_std(train_loader_ms)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 303,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_trans = transforms.Compose([transforms.ToTensor(), transforms.RandomHorizontalFlip(),transforms.RandomRotation(10),transforms.Normalize(mean,std)])\n",
    "\n",
    "test_trans = transforms.Compose([transforms.ToTensor(),transforms.Normalize(mean,std)])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 304,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_dataset = torchvision.datasets.ImageFolder(root = train_data_path, transform=train_trans)\n",
    "test_dataset = torchvision.datasets.ImageFolder(root = test_data_path, transform=test_trans)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 305,
   "metadata": {},
   "outputs": [],
   "source": [
    "def show_trans_img(dataset):\n",
    "    loader = torch.utils.data.DataLoader(dataset,batch_size = 6,shuffle=True)\n",
    "    batch = next(iter(loader))\n",
    "    Images,lables = batch\n",
    "    grid = torchvision.utils.make_grid(Images,nrow=3)\n",
    "    plt.figure(figsize=(11,11))\n",
    "    plt.imshow(np.transpose(grid,(1,2,0)))\n",
    "    print('lables:', lables)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 306,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_loader = torch.utils.data.DataLoader(train_dataset,batch_size=32,shuffle=True)\n",
    "test_loader = torch.utils.data.DataLoader(test_dataset,batch_size=32,shuffle=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 307,
   "metadata": {},
   "outputs": [],
   "source": [
    "def set_device():\n",
    "    if torch.cuda.is_available():\n",
    "        dev = 'cuda:0'\n",
    "    else:\n",
    "        dev = 'cpu'\n",
    "    return torch.device(dev)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 308,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torchvision.models as models\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "#chose a model, but set weights to None so you can train it yourself\n",
    "resnet_18_model = models.resnet18(weights=None)\n",
    "\n",
    "num_ftrs = resnet_18_model.fc.in_features\n",
    "number_of_classes = len(os.listdir('./train'))\n",
    "resnet_18_model.fc = nn.Linear(num_ftrs,number_of_classes)\n",
    "device = set_device()\n",
    "resnet_18_model = resnet_18_model.to(device)\n",
    "loss_fn = nn.CrossEntropyLoss()\n",
    "# lr 0.01 to 0.1 experminet whit it\n",
    "# momenntum makes gradient desecnt faster\n",
    "# weight_decay extra error to loss function , prevents overfiting\n",
    "optimizer = optim.SGD(resnet_18_model.parameters(),lr=0.01,momentum=0.9,weight_decay=0.003)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 309,
   "metadata": {},
   "outputs": [],
   "source": [
    "def evaluate_model_on_test_set(model,test_loader):\n",
    "    model.eval()\n",
    "    predicted_correctly_on_epoch = 0\n",
    "    total = 0\n",
    "    device =set_device()\n",
    "\n",
    "    with torch.no_grad():\n",
    "        for data in test_loader:\n",
    "            images , lables = data\n",
    "            images = images.to(device)\n",
    "            lables = lables.to(device)\n",
    "            total += lables.size(0)\n",
    "\n",
    "            outputs = model(images)\n",
    "\n",
    "            _ , predicted = torch.max(outputs.data,1)\n",
    "\n",
    "            predicted_correctly_on_epoch += (predicted == lables).sum().item()\n",
    "    \n",
    "    epoch_acc = 100.0 * predicted_correctly_on_epoch / total\n",
    "    print('     -Test dataset. Got %d out of %d images correctly(%.3f%%)' % (predicted_correctly_on_epoch,total, epoch_acc))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 310,
   "metadata": {},
   "outputs": [],
   "source": [
    "def save_checkpoint(state,filename = 'model_checkpoint.pth.tar'):\n",
    "    print('=> Saveing checkpoint')\n",
    "    torch.save(state,filename,_use_new_zipfile_serialization=False)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 311,
   "metadata": {},
   "outputs": [],
   "source": [
    "def load_checkpoint(checkpoint):\n",
    "    print('=> Loading checkpoint')\n",
    "    model.load_state_dict(checkpoint['state_dict'])\n",
    "    optimizer.load_state_dict(checkpoint['state_dict'])\n",
    "    epoch.load_state_dict(checkpoint['state_dict'])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 314,
   "metadata": {},
   "outputs": [],
   "source": [
    "def train_nn(model,train_loader,test_loader,criterion,optimizer,n_epoch):\n",
    "    device = set_device()\n",
    "    for epoch in range(n_epoch):\n",
    "        print('Epoch number %d' % (epoch + 1))\n",
    "        model.train()\n",
    "        running_loss = 0.0\n",
    "        running_correct = 0.0\n",
    "        total = 0\n",
    "        checkpoint = {'state_dict' : model.state_dict(), 'optimizer': optimizer.state_dict(), 'epoch': epoch}\n",
    "        save_checkpoint(checkpoint)\n",
    "        for data in train_loader:\n",
    "            images , lables = data\n",
    "            images = images.to(device)\n",
    "            lables = lables.to(device)\n",
    "            total += lables.size(0)\n",
    "\n",
    "            optimizer.zero_grad()\n",
    "\n",
    "            outputs = model(images)\n",
    "\n",
    "            _ , predicted = torch.max(outputs.data,1)\n",
    "\n",
    "            loss = criterion(outputs,lables)\n",
    "\n",
    "            loss.backward()\n",
    "            optimizer.step()\n",
    "\n",
    "            running_loss += loss.item()\n",
    "            running_correct += (lables == predicted).sum().item()\n",
    "\n",
    "        epoch_loss = running_loss/len(train_loader)\n",
    "        epoch_acc = 100.0 * running_correct / total\n",
    "\n",
    "        print(\"         -Training dataset. Got %d out of %d images correctly(%.3f%%). Epoch loss: %.3f\" % (running_correct,total,epoch_acc,epoch_loss))\n",
    "        evaluate_model_on_test_set(model,test_loader)\n",
    "        \n",
    "    print(\"Finished\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 315,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch number 1\n",
      "=> Saveing checkpoint\n",
      "         -Training dataset. Got 1373 out of 13572 images correctly(10.116%). Epoch loss: 3.908\n",
      "     -Test dataset. Got 84 out of 500 images correctly(16.800%)\n",
      "Epoch number 2\n",
      "=> Saveing checkpoint\n",
      "         -Training dataset. Got 3224 out of 13572 images correctly(23.755%). Epoch loss: 2.995\n",
      "     -Test dataset. Got 151 out of 500 images correctly(30.200%)\n",
      "Epoch number 3\n",
      "=> Saveing checkpoint\n",
      "         -Training dataset. Got 4434 out of 13572 images correctly(32.670%). Epoch loss: 2.558\n",
      "     -Test dataset. Got 174 out of 500 images correctly(34.800%)\n",
      "Epoch number 4\n",
      "=> Saveing checkpoint\n",
      "         -Training dataset. Got 5420 out of 13572 images correctly(39.935%). Epoch loss: 2.247\n",
      "     -Test dataset. Got 202 out of 500 images correctly(40.400%)\n",
      "Epoch number 5\n",
      "=> Saveing checkpoint\n",
      "         -Training dataset. Got 6289 out of 13572 images correctly(46.338%). Epoch loss: 1.998\n",
      "     -Test dataset. Got 168 out of 500 images correctly(33.600%)\n",
      "Epoch number 6\n",
      "=> Saveing checkpoint\n",
      "         -Training dataset. Got 6911 out of 13572 images correctly(50.921%). Epoch loss: 1.801\n",
      "     -Test dataset. Got 266 out of 500 images correctly(53.200%)\n",
      "Epoch number 7\n",
      "=> Saveing checkpoint\n",
      "         -Training dataset. Got 7493 out of 13572 images correctly(55.209%). Epoch loss: 1.640\n",
      "     -Test dataset. Got 282 out of 500 images correctly(56.400%)\n",
      "Epoch number 8\n",
      "=> Saveing checkpoint\n",
      "         -Training dataset. Got 7891 out of 13572 images correctly(58.142%). Epoch loss: 1.536\n",
      "     -Test dataset. Got 293 out of 500 images correctly(58.600%)\n",
      "Epoch number 9\n",
      "=> Saveing checkpoint\n",
      "         -Training dataset. Got 8312 out of 13572 images correctly(61.244%). Epoch loss: 1.418\n",
      "     -Test dataset. Got 308 out of 500 images correctly(61.600%)\n",
      "Epoch number 10\n",
      "=> Saveing checkpoint\n",
      "         -Training dataset. Got 8735 out of 13572 images correctly(64.360%). Epoch loss: 1.303\n",
      "     -Test dataset. Got 342 out of 500 images correctly(68.400%)\n",
      "Epoch number 11\n",
      "=> Saveing checkpoint\n"
     ]
    }
   ],
   "source": [
    "train_nn(resnet_18_model,train_loader,test_loader,loss_fn,optimizer,50)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.9.16 ('torch')",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.16"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "f3b09f0dae079356b11e2992c8ce1698bd60fda55aea4c87f004ec164747e9c6"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
